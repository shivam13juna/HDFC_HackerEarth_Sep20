{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "\n",
    "#Feature importance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "\n",
    "#importing machine learning libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "\n",
    "disable_eager_execution()\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "#Secondary imports\n",
    "import pandas_profiling as pp\n",
    "from scipy.stats import pearsonr\n",
    "import pickle\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (746,835) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (700,731,740,752,761,789,811,820,829,841,850) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "sample = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "cols = np.load('final_col.npy').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = []\n",
    "\n",
    "for i in range(len(cols)):\n",
    "    value = (1 - train[train[cols[i]]!=0].shape[0]/train.shape[0]) * 100\n",
    "    if value > 60:\n",
    "        remove.append(cols[i])\n",
    "\n",
    "\n",
    "for i in range(len(remove)):\n",
    "    cols.remove(remove[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding missing values, and selecting  columns with less than 5% missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "seta = cols.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_missing = train[seta].isnull().sum() * 100 / len(train[seta])\n",
    "missing_value_df = pd.DataFrame({'column_name': train[seta].columns,\n",
    "                                 'percent_missing': percent_missing})\n",
    "\n",
    "missing_value_df.sort_values('percent_missing', ascending=False, inplace=True)\n",
    "missing_value_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_col = missing_value_df[missing_value_df['percent_missing']<5].sort_values('percent_missing', ascending=False).column_name.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mis_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         importance\n",
      "Col10          0.03\n",
      "Col11          0.03\n",
      "Col168         0.03\n",
      "Col186         0.02\n",
      "Col25          0.02\n",
      "Col202         0.02\n",
      "Col196         0.02\n",
      "Col26          0.02\n",
      "Col205         0.02\n",
      "Col182         0.02\n",
      "Col188         0.02\n",
      "Col198         0.02\n",
      "Col591         0.01\n",
      "Col189         0.01\n",
      "Col120         0.01\n",
      "Col51          0.01\n",
      "Col75          0.01\n",
      "Col68          0.01\n",
      "Col49          0.01\n",
      "Col1688        0.01\n",
      "Col1272        0.01\n",
      "Col58          0.01\n",
      "Col44          0.01\n",
      "Col47          0.01\n",
      "Col1025        0.01\n",
      "Col1072        0.01\n",
      "Col1210        0.01\n",
      "Col1212        0.01\n",
      "Col1028        0.01\n",
      "Col1026        0.01\n",
      "...             ...\n",
      "Col1073        0.00\n",
      "Col1239        0.00\n",
      "Col1711        0.00\n",
      "Col63          0.00\n",
      "Col88          0.00\n",
      "Col1081        0.00\n",
      "Col1231        0.00\n",
      "Col60          0.00\n",
      "Col1235        0.00\n",
      "Col1215        0.00\n",
      "Col1347        0.00\n",
      "Col1143        0.00\n",
      "Col64          0.00\n",
      "Col61          0.00\n",
      "Col1057        0.00\n",
      "Col1185        0.00\n",
      "Col1241        0.00\n",
      "Col1527        0.00\n",
      "Col89          0.00\n",
      "Col1305        0.00\n",
      "Col1056        0.00\n",
      "Col1265        0.00\n",
      "Col1229        0.00\n",
      "Col1253        0.00\n",
      "Col86          0.00\n",
      "Col1009        0.00\n",
      "Col1631        0.00\n",
      "Col1221        0.00\n",
      "Col1589        0.00\n",
      "Col34          0.00\n",
      "\n",
      "[167 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "#Creating features from training dataset\n",
    "features1 = train[mis_col]\n",
    "\n",
    "\n",
    "targets = train['Col2']\n",
    "\n",
    "rf.fit(features1, targets) \n",
    "\n",
    "feature_importances = pd.DataFrame(rf.feature_importances_,\n",
    "                                   index = mis_col,\n",
    "                                    columns=['importance']).sort_values('importance',ascending=False)\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167\n"
     ]
    }
   ],
   "source": [
    "thres_col = sorted(feature_importances[feature_importances.importance > threshold].reset_index()['index'].values.tolist(), key = lambda x: int(x[3:]))\n",
    "print(len(thres_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres_col.remove('Col32')\n",
    "\n",
    "thres_col.remove('Col33')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres_col.append('Col3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f292c0b7400>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1,2)\n",
    "\n",
    "train['Col10'].plot(ax=axs[0])\n",
    "test['Col10'].plot(ax=axs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in thres_col:\n",
    "    if train[i].nunique() >= 11:\n",
    "        train[i] = train[i].ewm(span = 20).mean()\n",
    "        test[i] = test[i].ewm(span = 20).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello 0\n",
      "hello 1\n",
      "hello 2\n",
      "hello 3\n",
      "hello 4\n",
      "Average accuracy was:  0.8983505950403533\n"
     ]
    }
   ],
   "source": [
    "lgbb = lgb.LGBMClassifier()\n",
    "# ctb = CatBoostClassifier(verbose=False)\n",
    "\n",
    "# xgbb = xgb.XGBClassifier()\n",
    "\n",
    "n_split = 5\n",
    "avg1 = 0\n",
    "avg2 = 0\n",
    "count=0\n",
    "\n",
    "skf = StratifiedKFold(n_splits = n_split, shuffle = True)\n",
    "\n",
    "for train_index, test_index in skf.split(train[thres_col], train['Col2']):\n",
    "    print(\"hello\", count)\n",
    "    count+=1\n",
    "   \n",
    "    trainx, testx = train[thres_col].iloc[train_index], train[thres_col].iloc[test_index]\n",
    "    trainy, testy = train['Col2'].iloc[train_index], train['Col2'].iloc[test_index]\n",
    "    \n",
    "    lgbb.fit(trainx, trainy)\n",
    "#     ctb.fit(trainx, trainy)\n",
    "    avg1 += accuracy_score(lgbb.predict(testx), testy)\n",
    "#     avg2 += accuracy_score(ctb.predict(testx), testy)\n",
    "\n",
    "\n",
    "print(\"Average accuracy was: \", avg1/n_split)#,\"and\", avg2/6)0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f292bfccba8>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(lgbb.predict(testx), lgbb.predict(testx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy was:  0.8994920498439931\n"
     ]
    }
   ],
   "source": [
    "lgbb = LogisticRegression()\n",
    "# ctb = CatBoostClassifier(verbose=False)\n",
    "\n",
    "# xgbb = xgb.XGBClassifier()\n",
    "\n",
    "n_split = 5\n",
    "avg1 = 0\n",
    "avg2 = 0\n",
    "count=0\n",
    "\n",
    "skf = StratifiedKFold(n_splits = n_split, shuffle = True)\n",
    "\n",
    "for train_index, test_index in skf.split(train[thres_col], train['Col2']):\n",
    "    print(\"hello\", count)\n",
    "    count+=1\n",
    "   \n",
    "    trainx, testx = train[thres_col].iloc[train_index], train[thres_col].iloc[test_index]\n",
    "    trainy, testy = train['Col2'].iloc[train_index], train['Col2'].iloc[test_index]\n",
    "    \n",
    "    lgbb.fit(trainx, trainy)\n",
    "#     ctb.fit(trainx, trainy)\n",
    "    avg1 += accuracy_score(lgbb.predict(testx), testy)\n",
    "#     avg2 += accuracy_score(ctb.predict(testx), testy)\n",
    "\n",
    "\n",
    "print(\"Average accuracy was: \", avg1/n_split)#,\"and\", avg2/6)0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking, Embedding, GRU\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Embedding layer\n",
    "# Recurrent layer\n",
    "model.add(GRU(10, return_sequences=False, dropout=0.1, recurrent_dropout=0.1))\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train[thres_col].values\n",
    "train_target = train['Col2'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X, data_Y = [], []\n",
    "for i in range(len(train_data) - 7):\n",
    "    # find the end of this pattern\n",
    "    end_ix = i + 0\n",
    "    out_end_ix = end_ix + 7\n",
    "    data_X.append(train_data[end_ix:out_end_ix, :])\n",
    "    data_Y.append(train_target[end_ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X = np.array(data_X)\n",
    "data_Y = np.array(data_Y).reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17514, 7, 166)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17514, 1)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17521, 166)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0928 15:39:00.094004 139818031677568 deprecation.py:506] From /usr/local/lib/python3.5/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17514 samples\n",
      "17514/17514 [==============================] - 3s 187us/sample - loss: 0.3715 - accuracy: 0.8706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f292d5834a8>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data_X, data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17514, 2)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(data_X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0928 15:46:26.526282 139818031677568 callbacks.py:862] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    }
   ],
   "source": [
    "path_to_weigths = './current.hdf5'\n",
    "checkpoint = ModelCheckpoint(path_to_weigths, monitor='val_loss', verbose=1,\n",
    "                                save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss',patience=5, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello 0\n",
      "Train on 14010 samples, validate on 3504 samples\n",
      "Epoch 1/100\n",
      "14010/14010 [==============================] - 3s 188us/sample - loss: 0.3276 - accuracy: 0.8995 - val_loss: 0.3269 - val_accuracy: 0.8993\n",
      "Epoch 2/100\n",
      "14010/14010 [==============================] - 3s 184us/sample - loss: 0.3273 - accuracy: 0.8995 - val_loss: 0.3268 - val_accuracy: 0.8993\n",
      "Epoch 3/100\n",
      "14010/14010 [==============================] - 3s 184us/sample - loss: 0.3271 - accuracy: 0.8995 - val_loss: 0.3266 - val_accuracy: 0.8993\n",
      "Epoch 4/100\n",
      "14010/14010 [==============================] - 3s 183us/sample - loss: 0.3270 - accuracy: 0.8995 - val_loss: 0.3265 - val_accuracy: 0.8993\n",
      "Epoch 5/100\n",
      "14010/14010 [==============================] - 3s 189us/sample - loss: 0.3265 - accuracy: 0.8995 - val_loss: 0.3271 - val_accuracy: 0.8993\n",
      "Epoch 6/100\n",
      "14010/14010 [==============================] - 3s 182us/sample - loss: 0.3266 - accuracy: 0.8995 - val_loss: 0.3269 - val_accuracy: 0.8993\n",
      "Epoch 7/100\n",
      "14010/14010 [==============================] - 3s 183us/sample - loss: 0.3273 - accuracy: 0.8995 - val_loss: 0.3270 - val_accuracy: 0.8993\n",
      "Epoch 8/100\n",
      "14010/14010 [==============================] - 3s 184us/sample - loss: 0.3263 - accuracy: 0.8995 - val_loss: 0.3268 - val_accuracy: 0.8993\n",
      "Epoch 9/100\n",
      "14010/14010 [==============================] - 3s 185us/sample - loss: 0.3265 - accuracy: 0.8995 - val_loss: 0.3273 - val_accuracy: 0.8993\n",
      "hello 1\n",
      "Train on 14011 samples, validate on 3503 samples\n",
      "Epoch 1/100\n",
      "14011/14011 [==============================] - 3s 186us/sample - loss: 0.3270 - accuracy: 0.8994 - val_loss: 0.3266 - val_accuracy: 0.8995\n",
      "Epoch 2/100\n",
      "14011/14011 [==============================] - 3s 184us/sample - loss: 0.3267 - accuracy: 0.8994 - val_loss: 0.3265 - val_accuracy: 0.8995\n",
      "Epoch 3/100\n",
      "14011/14011 [==============================] - 3s 186us/sample - loss: 0.3268 - accuracy: 0.8994 - val_loss: 0.3268 - val_accuracy: 0.8995\n",
      "Epoch 4/100\n",
      "14011/14011 [==============================] - 3s 185us/sample - loss: 0.3268 - accuracy: 0.8994 - val_loss: 0.3267 - val_accuracy: 0.8995\n",
      "Epoch 5/100\n",
      "14011/14011 [==============================] - 3s 185us/sample - loss: 0.3265 - accuracy: 0.8994 - val_loss: 0.3271 - val_accuracy: 0.8995\n",
      "Epoch 6/100\n",
      "14011/14011 [==============================] - 3s 189us/sample - loss: 0.3269 - accuracy: 0.8994 - val_loss: 0.3266 - val_accuracy: 0.8995\n",
      "Epoch 7/100\n",
      "14011/14011 [==============================] - 2s 174us/sample - loss: 0.3267 - accuracy: 0.8994 - val_loss: 0.3265 - val_accuracy: 0.8995\n",
      "Epoch 8/100\n",
      "14011/14011 [==============================] - 3s 200us/sample - loss: 0.3266 - accuracy: 0.8994 - val_loss: 0.3271 - val_accuracy: 0.8995\n",
      "Epoch 9/100\n",
      "14011/14011 [==============================] - 3s 204us/sample - loss: 0.3267 - accuracy: 0.8994 - val_loss: 0.3267 - val_accuracy: 0.8995\n",
      "Epoch 10/100\n",
      "14011/14011 [==============================] - 3s 179us/sample - loss: 0.3267 - accuracy: 0.8995 - val_loss: 0.3268 - val_accuracy: 0.8995\n",
      "Epoch 11/100\n",
      "14011/14011 [==============================] - 3s 179us/sample - loss: 0.3267 - accuracy: 0.8994 - val_loss: 0.3266 - val_accuracy: 0.8995\n",
      "Epoch 12/100\n",
      "14011/14011 [==============================] - 2s 173us/sample - loss: 0.3266 - accuracy: 0.8994 - val_loss: 0.3265 - val_accuracy: 0.8995\n",
      "hello 2\n",
      "Train on 14011 samples, validate on 3503 samples\n",
      "Epoch 1/100\n",
      "14011/14011 [==============================] - 2s 172us/sample - loss: 0.3267 - accuracy: 0.8994 - val_loss: 0.3264 - val_accuracy: 0.8995\n",
      "Epoch 2/100\n",
      "14011/14011 [==============================] - 2s 172us/sample - loss: 0.3270 - accuracy: 0.8994 - val_loss: 0.3263 - val_accuracy: 0.8995\n",
      "Epoch 3/100\n",
      "14011/14011 [==============================] - 3s 188us/sample - loss: 0.3266 - accuracy: 0.8995 - val_loss: 0.3266 - val_accuracy: 0.8995\n",
      "Epoch 4/100\n",
      "14011/14011 [==============================] - 3s 195us/sample - loss: 0.3265 - accuracy: 0.8994 - val_loss: 0.3272 - val_accuracy: 0.8995\n",
      "Epoch 5/100\n",
      "14011/14011 [==============================] - 3s 198us/sample - loss: 0.3271 - accuracy: 0.8994 - val_loss: 0.3263 - val_accuracy: 0.8995\n",
      "Epoch 6/100\n",
      "14011/14011 [==============================] - 3s 197us/sample - loss: 0.3269 - accuracy: 0.8994 - val_loss: 0.3266 - val_accuracy: 0.8995\n",
      "Epoch 7/100\n",
      "14011/14011 [==============================] - 3s 194us/sample - loss: 0.3265 - accuracy: 0.8994 - val_loss: 0.3269 - val_accuracy: 0.8995\n",
      "Epoch 8/100\n",
      "14011/14011 [==============================] - 3s 187us/sample - loss: 0.3268 - accuracy: 0.8994 - val_loss: 0.3264 - val_accuracy: 0.8995\n",
      "Epoch 9/100\n",
      "14011/14011 [==============================] - 3s 186us/sample - loss: 0.3270 - accuracy: 0.8994 - val_loss: 0.3263 - val_accuracy: 0.8995\n",
      "Epoch 10/100\n",
      "14011/14011 [==============================] - 3s 191us/sample - loss: 0.3265 - accuracy: 0.8994 - val_loss: 0.3266 - val_accuracy: 0.8995\n",
      "hello 3\n",
      "Train on 14012 samples, validate on 3502 samples\n",
      "Epoch 1/100\n",
      "14012/14012 [==============================] - 3s 187us/sample - loss: 0.3271 - accuracy: 0.8993 - val_loss: 0.3263 - val_accuracy: 0.8995\n",
      "Epoch 2/100\n",
      "14012/14012 [==============================] - 3s 185us/sample - loss: 0.3268 - accuracy: 0.8994 - val_loss: 0.3264 - val_accuracy: 0.8995\n",
      "Epoch 3/100\n",
      "14012/14012 [==============================] - 3s 186us/sample - loss: 0.3267 - accuracy: 0.8994 - val_loss: 0.3267 - val_accuracy: 0.8995\n",
      "Epoch 4/100\n",
      "14012/14012 [==============================] - 3s 188us/sample - loss: 0.3269 - accuracy: 0.8994 - val_loss: 0.3263 - val_accuracy: 0.8995\n",
      "Epoch 5/100\n",
      "14012/14012 [==============================] - 3s 187us/sample - loss: 0.3266 - accuracy: 0.8994 - val_loss: 0.3272 - val_accuracy: 0.8995\n",
      "Epoch 6/100\n",
      "14012/14012 [==============================] - 3s 184us/sample - loss: 0.3267 - accuracy: 0.8994 - val_loss: 0.3265 - val_accuracy: 0.8995\n",
      "Epoch 7/100\n",
      "14012/14012 [==============================] - 3s 185us/sample - loss: 0.3269 - accuracy: 0.8994 - val_loss: 0.3263 - val_accuracy: 0.8995\n",
      "Epoch 8/100\n",
      "14012/14012 [==============================] - 3s 186us/sample - loss: 0.3267 - accuracy: 0.8994 - val_loss: 0.3266 - val_accuracy: 0.8995\n",
      "Epoch 9/100\n",
      "14012/14012 [==============================] - 3s 184us/sample - loss: 0.3268 - accuracy: 0.8994 - val_loss: 0.3263 - val_accuracy: 0.8995\n",
      "Epoch 10/100\n",
      "14012/14012 [==============================] - 3s 186us/sample - loss: 0.3267 - accuracy: 0.8995 - val_loss: 0.3265 - val_accuracy: 0.8995\n",
      "Epoch 11/100\n",
      "14012/14012 [==============================] - 3s 186us/sample - loss: 0.3269 - accuracy: 0.8994 - val_loss: 0.3277 - val_accuracy: 0.8995\n",
      "Epoch 12/100\n",
      "14012/14012 [==============================] - 3s 186us/sample - loss: 0.3272 - accuracy: 0.8994 - val_loss: 0.3267 - val_accuracy: 0.8995\n",
      "Epoch 13/100\n",
      "14012/14012 [==============================] - 3s 184us/sample - loss: 0.3266 - accuracy: 0.8994 - val_loss: 0.3264 - val_accuracy: 0.8995\n",
      "Epoch 14/100\n",
      "14012/14012 [==============================] - 3s 185us/sample - loss: 0.3269 - accuracy: 0.8994 - val_loss: 0.3263 - val_accuracy: 0.8995\n",
      "hello 4\n",
      "Train on 14012 samples, validate on 3502 samples\n",
      "Epoch 1/100\n",
      "14012/14012 [==============================] - 3s 186us/sample - loss: 0.3269 - accuracy: 0.8994 - val_loss: 0.3264 - val_accuracy: 0.8995\n",
      "Epoch 2/100\n",
      "14012/14012 [==============================] - 3s 185us/sample - loss: 0.3267 - accuracy: 0.8994 - val_loss: 0.3263 - val_accuracy: 0.8995\n",
      "Epoch 3/100\n",
      "14012/14012 [==============================] - 3s 193us/sample - loss: 0.3265 - accuracy: 0.8994 - val_loss: 0.3288 - val_accuracy: 0.8995\n",
      "Epoch 4/100\n",
      "14012/14012 [==============================] - 3s 189us/sample - loss: 0.3269 - accuracy: 0.8994 - val_loss: 0.3264 - val_accuracy: 0.8995\n",
      "Epoch 5/100\n",
      "14012/14012 [==============================] - 3s 187us/sample - loss: 0.3266 - accuracy: 0.8994 - val_loss: 0.3265 - val_accuracy: 0.8995\n",
      "Epoch 6/100\n",
      "14012/14012 [==============================] - 3s 199us/sample - loss: 0.3268 - accuracy: 0.8994 - val_loss: 0.3263 - val_accuracy: 0.8995\n",
      "Epoch 7/100\n",
      "14012/14012 [==============================] - 3s 214us/sample - loss: 0.3266 - accuracy: 0.8994 - val_loss: 0.3264 - val_accuracy: 0.8995\n",
      "Average accuracy was:  0.8994518820453967\n"
     ]
    }
   ],
   "source": [
    "lgbb = LogisticRegression()\n",
    "# ctb = CatBoostClassifier(verbose=False)\n",
    "\n",
    "# xgbb = xgb.XGBClassifier()\n",
    "\n",
    "n_split = 5\n",
    "avg1 = 0\n",
    "avg2 = 0\n",
    "count=0\n",
    "\n",
    "skf = StratifiedKFold(n_splits = n_split, shuffle = True)\n",
    "\n",
    "for train_index, test_index in skf.split(data_X, data_Y):\n",
    "    print(\"hello\", count)\n",
    "    count+=1\n",
    "   \n",
    "    trainx, testx = data_X[train_index], data_X[test_index]\n",
    "    trainy, testy = data_Y[train_index], data_Y[test_index]\n",
    "    \n",
    "    model.fit(trainx, trainy,\n",
    "             validation_data=(testx, testy),\n",
    "             callbacks = [early_stopping], \n",
    "             epochs = 100)\n",
    "#     ctb.fit(trainx, trainy)\n",
    "    avg1 += accuracy_score(np.argmax(model.predict(testx), axis=1), testy)\n",
    "#     avg2 += accuracy_score(ctb.predict(testx), testy)\n",
    "\n",
    "\n",
    "print(\"Average accuracy was: \", avg1/n_split)#,\"and\", avg2/6)0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbb = lgb.LGBMClassifier()\n",
    "lgbb.fit(train[thres_col].values, train['Col2'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = lgbb.predict(test[thres_col].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test[thres_col].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    test_data.append(test_data[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.array(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata_X = []\n",
    "for i in range(len(test_data) - 7):\n",
    "    # find the end of this pattern\n",
    "    end_ix = i + 0\n",
    "    out_end_ix = end_ix + 7\n",
    "    tdata_X.append(test_data[end_ix:out_end_ix, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata_X.append(tdata_X[-1])\n",
    "tdata_X.append(tdata_X[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata_X = np.array(tdata_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20442, 7, 166)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20442, 2394)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17514 samples\n",
      "Epoch 1/7\n",
      "17514/17514 [==============================] - 3s 166us/sample - loss: 0.3266 - accuracy: 0.8995\n",
      "Epoch 2/7\n",
      "17514/17514 [==============================] - 3s 164us/sample - loss: 0.3265 - accuracy: 0.8995\n",
      "Epoch 3/7\n",
      "17514/17514 [==============================] - 3s 165us/sample - loss: 0.3267 - accuracy: 0.8995\n",
      "Epoch 4/7\n",
      "17514/17514 [==============================] - 3s 165us/sample - loss: 0.3268 - accuracy: 0.8995\n",
      "Epoch 5/7\n",
      "17514/17514 [==============================] - 3s 164us/sample - loss: 0.3267 - accuracy: 0.8995\n",
      "Epoch 6/7\n",
      "17514/17514 [==============================] - 3s 166us/sample - loss: 0.3267 - accuracy: 0.8995\n",
      "Epoch 7/7\n",
      "17514/17514 [==============================] - 3s 164us/sample - loss: 0.3263 - accuracy: 0.8995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2929f57048>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data_X, data_Y, epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(tdata_X).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0]), array([20442]))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(result, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['Col1'] = test['Col1']\n",
    "submission['Col2'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RIGD58ZWD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RIH660YDS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RIH660Q96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RIYDO15W1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RIYBGC1ZD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Col1  Col2\n",
       "0  RIGD58ZWD     0\n",
       "1  RIH660YDS     0\n",
       "2  RIH660Q96     0\n",
       "3  RIYDO15W1     0\n",
       "4  RIYBGC1ZD     0"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
